{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bda67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "üîß Model: HuggingFaceTB/SmolLM2-135M\n",
      "üñ•Ô∏è  Cihaz: GPU\n",
      "üîß Model: HuggingFaceTB/SmolLM2-135M\n",
      "üñ•Ô∏è  Cihaz: GPU\n",
      "‚úÖ Model GPU'ya y√ºklendi\n",
      "‚úÖ Model GPU'ya y√ºklendi\n",
      "üìä Eƒüitim: 40 | Test: 10 √∂rnek\n",
      "üìä Eƒüitim: 40 | Test: 10 √∂rnek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 2279.92 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 2279.92 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 1766.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Eƒüitim ba≈ülƒ±yor (50 √∂rnek, 2 epoch)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.909700</td>\n",
       "      <td>1.735289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.236100</td>\n",
       "      <td>1.692337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Eƒüitim tamamlandƒ±! Model 'smollm_mini_finetuned' klas√∂r√ºne kaydedildi.\n",
      "üìå Bu √ßok k√º√ß√ºk bir √∂rnektir. Ger√ßek eƒüitim i√ßin daha fazla veri kullanƒ±n.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1) GEREKLƒ∞ K√úT√úPHANELERƒ∞N KURULUMU\n",
    "# -----------------------------------------------------------\n",
    "!pip install transformers datasets accelerate sentencepiece -q\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2) BASIT VE HIZLI Eƒûƒ∞Tƒ∞M (CPU/GPU Hibrit)\n",
    "# -----------------------------------------------------------\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# Bellek temizliƒüi\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "MODEL_NAME = \"HuggingFaceTB/SmolLM2-135M\"  # 360M ‚Üí 135M (√ßok daha k√º√ß√ºk model)\n",
    "\n",
    "print(f\"üîß Model: {MODEL_NAME}\")\n",
    "print(f\"üñ•Ô∏è  Cihaz: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3) TOKENIZER\n",
    "# -----------------------------------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.padding_side = \"right\"  ##   aa  saƒüdkasdkas aa\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4) MODEL (Basit FP32 veya FP16)\n",
    "# -----------------------------------------------------------\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# GPU varsa modeli GPU'ya ta≈üƒ±\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    print(\"‚úÖ Model GPU'ya y√ºklendi\")\n",
    "else:\n",
    "    print(\"‚úÖ Model CPU'da √ßalƒ±≈üƒ±yor\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5) DATASET (√áOK K√ú√á√úK - Hƒ±zlƒ± test i√ßin)\n",
    "# -----------------------------------------------------------\n",
    "dataset = load_dataset(\"vicgalle/alpaca-gpt4\", split=\"train[:50]\")  # Sadece 50 √∂rnek!\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "print(f\"üìä Eƒüitim: {len(dataset['train'])} | Test: {len(dataset['test'])} √∂rnek\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6) TOKENIZATION (Kƒ±sa metinler)\n",
    "# -----------------------------------------------------------\n",
    "def format_example(example):\n",
    "    instruction = example[\"instruction\"]\n",
    "    response = example[\"output\"][:100]  # Response'u kƒ±salt\n",
    "    \n",
    "    prompt = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n{response}\"\n",
    "    \n",
    "    encoded = tokenizer(\n",
    "        prompt,\n",
    "        max_length=64,  # √áok kƒ±sa tokenlar\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    encoded[\"labels\"] = encoded[\"input_ids\"].copy()\n",
    "    return encoded\n",
    "\n",
    "dataset = dataset.map(\n",
    "    format_example,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 7) DATA COLLATOR\n",
    "# -----------------------------------------------------------\n",
    "collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 8) EƒûITIM PARAMETRELERI (Minimal)\n",
    "# -----------------------------------------------------------\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"smollm_mini_finetuned\",\n",
    "    per_device_train_batch_size=2,  # K√º√ß√ºk batch\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=2,  # 2 epoch\n",
    "    fp16=torch.cuda.is_available(),  # GPU varsa FP16\n",
    "    logging_steps=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\",\n",
    "    no_cuda=not torch.cuda.is_available(),  # CPU varsa no_cuda=True\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 9) TRAINER\n",
    "# -----------------------------------------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 10) EƒûITIM\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\nüöÄ Eƒüitim ba≈ülƒ±yor (50 √∂rnek, 2 epoch)...\")\n",
    "trainer.train()\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 11) KAYDETME\n",
    "# -----------------------------------------------------------\n",
    "trainer.save_model(\"smollm_mini_finetuned\")\n",
    "tokenizer.save_pretrained(\"smollm_mini_finetuned\")\n",
    "\n",
    "print(\"\\n‚úÖ Eƒüitim tamamlandƒ±! Model 'smollm_mini_finetuned' klas√∂r√ºne kaydedildi.\")\n",
    "print(\"üìå Bu √ßok k√º√ß√ºk bir √∂rnektir. Ger√ßek eƒüitim i√ßin daha fazla veri kullanƒ±n.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fdfbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Model Test Sonu√ßlarƒ±:\n",
      "================================================================================\n",
      "\n",
      "1. Prompt: Explain machine learning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cevap: Explain machine learning:\n",
      "\n",
      "Machine learning algorithms are used to find patterns in data for a variety of tasks. With machine learning, we can use algorithms to find patterns in data. For example, machine learning algorithms can be used to predict the weather.\n",
      "\n",
      "Machine learning is a branch of artificial intelligence (AI) that uses algorithms to find patterns in data. We can use machine learning algorithms to predict the weather.\n",
      "\n",
      "Machine learning algorithms are used to find patterns in data.\n",
      "\n",
      "Machine learning algorithms can be used to find patterns in data.\n",
      "\n",
      "Machine learning algorithms can be used to find patterns in data.\n",
      "\n",
      "Machine learning is a branch of artificial intelligence (AI). AI refers to the use of computers to think and act like humans. Machine learning is a type of AI that uses algorithms and data to find patterns in data.\n",
      "\n",
      "Machine learning algorithms are used to find patterns in data.\n",
      "\n",
      "Machine learning algorithms can be used to find patterns in data.\n",
      "\n",
      "Machine learning algorithms are used to find patterns in data.\n",
      "\n",
      "Machine learning algorithms can be used to find patterns in data.\n",
      "\n",
      "Machine learning algorithms can be used to find patterns in data.\n",
      "\n",
      "Machine learning algorithms can be used to find patterns in data.\n",
      "\n",
      "Machine learning algorithms can be used to\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Prompt: What is AI?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cevap: What is AI?\n",
      "\n",
      "Artificial Intelligence (AI) is a rapidly evolving field that uses computer systems to mimic human intelligence processes such as problem solving, decision making, and language translation. Over the past few decades, AI has been applied across various industries, including healthcare, finance, transportation, and manufacturing. However, its potential impacts on our daily lives and society are still largely unknown.\n",
      "\n",
      "Section 1: Defining AI\n",
      "\n",
      "To understand AI better, let's break down the term into simpler terms:\n",
      "\n",
      "* Artificial: Artificial in reference to human-like creations.\n",
      "* Intelligence: Ability to understand, process information, and adapt to new situations.\n",
      "* Intelligence Machines: Devices that simulate human cognition.\n",
      "* Intelligence Machines: Devices that perform tasks that normally require human intelligence.\n",
      "\n",
      "In simple terms, AI refers to the ability of a computer system to perform tasks that typically require human intelligence. These tasks may include understanding spoken language, recognizing objects, generating creative works, or even predicting future events.\n",
      "\n",
      "Section 2: Applications of AI\n",
      "\n",
      "Applications of AI range from simple home automation systems like thermostats and lighting controls to complex artificial intelligence algorithms used in businesses, healthcare, and finance. Some common applications of AI include:\n",
      "\n",
      "* Personalized Customer Service: Machine\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Prompt: How do transformers work?\n",
      "   Cevap: How do transformers work?\n",
      "\n",
      "Transformers are the most basic of electrical devices. They are simply coils of wire that are wound in a coil. The magnetic field of the current passing through the coils is created by the magnetic field of the voltage.\n",
      "\n",
      "The voltage is defined by the number of times the coils are turned on and off. The number of turns of wire increases the magnetic field and reduces the current for a given magnetic field.\n",
      "\n",
      "What is the life of a transformer?\n",
      "\n",
      "If the wire ends of the coil have been cut out, the transformer will have a short circuit. When the voltage is applied to the end of the coil, a current is produced. To keep the current flowing, the coils are re-wound. The current is then reduced to a steady level by applying a load to the end of the coil.\n",
      "\n",
      "The transformer is an important part of electrical engineering. It allows us to change the direction and/or magnitude of electrical current.\n",
      "\n",
      "What is a transformer?\n",
      "\n",
      "Transformers are electrical devices that convert one form of electrical energy to another. They are used to change the direction of a single electrical current.\n",
      "\n",
      "A transformer can also be used to change the voltage of an electrical load to the same level as the primary current.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ Test tamamlandƒ±!\n",
      "   Cevap: How do transformers work?\n",
      "\n",
      "Transformers are the most basic of electrical devices. They are simply coils of wire that are wound in a coil. The magnetic field of the current passing through the coils is created by the magnetic field of the voltage.\n",
      "\n",
      "The voltage is defined by the number of times the coils are turned on and off. The number of turns of wire increases the magnetic field and reduces the current for a given magnetic field.\n",
      "\n",
      "What is the life of a transformer?\n",
      "\n",
      "If the wire ends of the coil have been cut out, the transformer will have a short circuit. When the voltage is applied to the end of the coil, a current is produced. To keep the current flowing, the coils are re-wound. The current is then reduced to a steady level by applying a load to the end of the coil.\n",
      "\n",
      "The transformer is an important part of electrical engineering. It allows us to change the direction and/or magnitude of electrical current.\n",
      "\n",
      "What is a transformer?\n",
      "\n",
      "Transformers are electrical devices that convert one form of electrical energy to another. They are used to change the direction of a single electrical current.\n",
      "\n",
      "A transformer can also be used to change the voltage of an electrical load to the same level as the primary current.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ Test tamamlandƒ±!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Eƒüitilmi≈ü modeli y√ºkle\n",
    "pipe = pipeline(\"text-generation\", model=\"smollm_mini_finetuned\", tokenizer=\"smollm_mini_finetuned\")\n",
    "\n",
    "# Test prompts\n",
    "test_prompts = [\n",
    "    \"Explain machine learning:\",\n",
    "    \"What is AI?\",\n",
    "    \"How do transformers work?\"\n",
    "]\n",
    "\n",
    "print(\"ü§ñ Model Test Sonu√ßlarƒ±:\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"{i}. Prompt: {prompt}\")\n",
    "    result = pipe(prompt, max_length=100, num_return_sequences=1)[0][\"generated_text\"]\n",
    "    print(f\"   Cevap: {result}\")\n",
    "    print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Test tamamlandƒ±!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
