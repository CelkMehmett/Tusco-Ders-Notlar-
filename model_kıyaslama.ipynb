{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ce493c",
      "metadata": {
        "id": "e7ce493c"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers datasets accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2ade509a",
      "metadata": {
        "id": "2ade509a",
        "outputId": "95f00511-9441-4dd8-ef4e-68a78f955cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ğŸ“š Veri Seti YÃ¼kleniyor: CNN/DailyMail (Haber Makaleleri) ---\n",
            "\n",
            "*** ğŸ“° SeÃ§ilen Haber Metni (Ä°lk 150 Karakter): ***\n",
            "(CNN)One hundred and forty-seven victims. Many more families affected. Even more broken hopes and dreams. As Kenyans mourned those killed last week in...\n",
            "\n",
            "\n",
            "--- ğŸ“‘ T5: Makale Ã–zetleme (Encoder-Decoder) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**T5 Ã–zet:** the hashtag #47notjustanumber is a reference to the number of people killed at garissa university . the attacks in Kenya killed 142 students, three security officers and two security personnel . many more families affected by the attacks .\n",
            "------------------------------------------------------------\n",
            "\n",
            "--- ğŸ§  BERT: Soru Cevaplama (Encoder) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soru: What happened in this article?\n",
            "Cevap: **dreams died with his son** (GÃ¼ven: %3.87)\n",
            "------------------------------------------------------------\n",
            "\n",
            "--- ğŸ“ GPT: Metin DevamÄ± Ãœretimi (Decoder) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=56) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Girdi (Makalenin sonu): ...acks. The Interior Ministry has identified one of the attackers killed by security forces as the son of a government official. The father of suspect A\n",
            "**GPT Eklemesi (DevamÄ±):** imee Othman told Reuters that he had been staying in a hotel room in the vicinity of the attack when gunmen opened fire. Othman, a member of Egypt's security forces, was shot in the abdomen and was taken to a hospital for treatment. He was later released.\n",
            "\n",
            "The attack comes amid a wave of violence in the country, at least two suicide bombings in Cairo and a stabbing attack in Cairo's Tahrir Square on Wednesday.\n",
            "\n",
            "The attacks, which have killed more than 500 people, follow an uptick in attacks in recent weeks that have left more than 100 dead, according to security sources.\n",
            "\n",
            "On Wednesday, al-Ansari, the youngest of the attackers, was shot and killed in western Cairo while leaving a party celebrating Eid al-Fitr, the Muslim holiday of remembrance, a security source said.\n",
            "\n",
            "\"We were there for Eid al-Fitr and he was there for Eid al-Fitr,\" said another security source, who asked not to be named to avoid jeopardizing any future operations in Egypt. \"He was a son of a minister and minister of state and he was a son of a minister of state and minister.\"\n",
            "\n",
            "The head of the security forces, Mohamed al-Makh\n",
            "------------------------------------------------------------\n",
            "\n",
            "âœ… TÃ¼m model karÅŸÄ±laÅŸtÄ±rmalarÄ± tamamlandÄ±!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline, set_seed\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "# --- 1. Veri Setini YÃ¼kleme ve HazÄ±rlama ---\n",
        "print(\"--- ğŸ“š Veri Seti YÃ¼kleniyor: CNN/DailyMail (Haber Makaleleri) ---\")\n",
        "\n",
        "# Hugging Face Datasets'ten CNN/DailyMail veri setini yÃ¼kle\n",
        "# \"article\" alanÄ± haber makalesini iÃ§erir.\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test[:100]\")  # Ä°lk 100 Ã¶rneÄŸi al\n",
        "# Rastgele bir makale Ã¶rneÄŸi seÃ§elim\n",
        "random_index = random.randint(0, len(dataset) - 1)\n",
        "sample = dataset[random_index]\n",
        "\n",
        "ARTICLE_INPUT = sample['article']\n",
        "# Metin 512 token sÄ±nÄ±rÄ±nÄ± aÅŸmamasÄ± iÃ§in kÄ±saltÄ±labilir\n",
        "ARTICLE_INPUT = ARTICLE_INPUT[:1500]\n",
        "\n",
        "print(f\"\\n*** ğŸ“° SeÃ§ilen Haber Metni (Ä°lk 150 Karakter): ***\\n{ARTICLE_INPUT[:150]}...\\n\")\n",
        "\n",
        "# --- 2. T5: Makale Ã–zetleme (Summarization) ---\n",
        "def run_t5_summarization(text):\n",
        "    \"\"\"Verilen haber makalesini kÄ±sa ve tek cÃ¼mlelik bir baÅŸlÄ±k Ã¶zeti haline getirir.\"\"\"\n",
        "    print(\"\\n--- ğŸ“‘ T5: Makale Ã–zetleme (Encoder-Decoder) ---\")\n",
        "\n",
        "    # T5 Ã¶zetleme iÃ§in iyi bir seÃ§imdir.\n",
        "    summarizer = pipeline('summarization', model='t5-small')  # t5-small daha hÄ±zlÄ±\n",
        "\n",
        "    # Ã–zeti Ã§alÄ±ÅŸtÄ±rma\n",
        "    summary_result = summarizer(\n",
        "        text,\n",
        "        max_length=60,  # KÄ±sa bir Ã¶zet\n",
        "        min_length=20,\n",
        "        do_sample=False\n",
        "    )[0]['summary_text']\n",
        "\n",
        "    print(f\"**T5 Ã–zet:** {summary_result}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "\n",
        "# --- 3. BERT: Soru Cevaplama (Question Answering) ---\n",
        "def run_bert_qa(text):\n",
        "    \"\"\"Makale metni iÃ§indeki bir soruya cevap bulur.\"\"\"\n",
        "    print(\"\\n--- ğŸ§  BERT: Soru Cevaplama (Encoder) ---\")\n",
        "\n",
        "    # Soru Cevaplama (Question Answering) iÃ§in optimize edilmiÅŸ bir model\n",
        "    qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "    # Metne uygun bir soru tanÄ±mlayalÄ±m\n",
        "    question = \"What happened in this article?\"\n",
        "\n",
        "    # CevabÄ± Ã§alÄ±ÅŸtÄ±rma\n",
        "    result = qa_pipeline(question=question, context=text)\n",
        "\n",
        "    print(f\"Soru: {question}\")\n",
        "    print(f\"Cevap: **{result['answer']}** (GÃ¼ven: %{result['score']*100:.2f})\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "\n",
        "# --- 4. GPT: Makaleyi Devam Ettirme (Generation) ---\n",
        "def run_gpt_generation(text):\n",
        "    \"\"\"Makalenin sonuna baÄŸlamsal olarak uygun bir cÃ¼mle Ã¼retir.\"\"\"\n",
        "    print(\"\\n--- ğŸ“ GPT: Metin DevamÄ± Ãœretimi (Decoder) ---\")\n",
        "    set_seed(42)  # Tekrarlanabilir sonuÃ§lar iÃ§in\n",
        "\n",
        "    # GiriÅŸ olarak makalenin son 150 karakterini kullan\n",
        "    prompt = text[-150:]\n",
        "\n",
        "    # Metin Ãœretimi iÃ§in pipeline oluÅŸturma\n",
        "    generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "    # Ãœretimi Ã§alÄ±ÅŸtÄ±rma\n",
        "    generated_text = generator(\n",
        "        prompt,\n",
        "        max_length=len(prompt.split()) + 30, # Mevcut metin + 30 token daha\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        temperature=0.7 # AkÄ±cÄ± bir devam iÃ§in\n",
        "    )[0]['generated_text']\n",
        "\n",
        "    # Ãœretilen metnin sadece eklenen kÄ±smÄ±nÄ± gÃ¶stermek iÃ§in\n",
        "    added_text = generated_text[len(prompt):].strip()\n",
        "\n",
        "    print(f\"Girdi (Makalenin sonu): ...{prompt.strip()}\")\n",
        "    print(f\"**GPT Eklemesi (DevamÄ±):** {added_text}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "\n",
        "# --- 5. Modelleri Ã‡alÄ±ÅŸtÄ±r ---\n",
        "# 1. T5'i Ã‡alÄ±ÅŸtÄ±r (Ã–zetleme)\n",
        "run_t5_summarization(ARTICLE_INPUT)\n",
        "\n",
        "# 2. BERT'Ã¼ Ã‡alÄ±ÅŸtÄ±r (Soru Cevaplama)\n",
        "# Not: Cevap makale iÃ§inde tam olarak geÃ§melidir.\n",
        "run_bert_qa(ARTICLE_INPUT)\n",
        "\n",
        "# 3. GPT'yi Ã‡alÄ±ÅŸtÄ±r (Metin Ãœretme)\n",
        "run_gpt_generation(ARTICLE_INPUT)\n",
        "\n",
        "print(\"\\nâœ… TÃ¼m model karÅŸÄ±laÅŸtÄ±rmalarÄ± tamamlandÄ±!\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
